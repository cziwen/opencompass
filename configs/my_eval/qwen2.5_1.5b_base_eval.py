# configs/my_eval/qwen2p5_1p5b_fin_eval.py
from mmengine.config import read_base

with read_base():  # è®© OpenCompass è‡ªåŠ¨è¡¥ import
    # â†“â†“â†“ åªè¦åœ¨ with read_base é‡Œ importï¼Œå°±èƒ½è®©åé¢ dict é‡Œå†™å­—ç¬¦ä¸²ç±»å‹
    from opencompass.datasets.myfindataset import MyFinDataset          # ä½ çš„æ•°æ®é›†
    from opencompass.openicl.icl_retriever import ZeroRetriever         # ç®€å• 0-shot æ£€ç´¢å™¨
    from opencompass.openicl.icl_inferencer import GenInferencer        # é€šç”¨æ¨ç†å™¨
    from opencompass.openicl.icl_prompt_template import PromptTemplate  # Prompt æ¨¡æ¿
    from opencompass.openicl.icl_evaluator import RougeEvaluator        # ROUGE è¯„æµ‹

# ---------------------------------------------------------------------
# 1. è¯„æµ‹å…¬å…±é…ç½®
# ---------------------------------------------------------------------
default_eval_cfg = dict(
    evaluator=dict(type=RougeEvaluator),   # ä½¿ç”¨ ROUGE è¯„ä»·
    pred_role='BOT',
    pred_postprocessor=dict(type='strip')
)

# ---------------------------------------------------------------------
# 2. æ•°æ®é›†
# ---------------------------------------------------------------------
datasets = [
    dict(
        type=MyFinDataset,
        abbr='finqa1k_nihar',
        path='MyData/NiharS_financial_qa_1K_alpaca.jsonl',
        reader_cfg=dict(
            input_columns=['instruction', 'input'],
            output_column='output',
        ),
        infer_cfg=dict(                         # â˜… æ¨ç†é…ç½®å¿…é¡»å« retriever ä¸ inferencer
            prompt_template=dict(
                type=PromptTemplate,
                template='''### Instruction:
{instruction}

### Input:
{input}

### Response:'''),
            retriever=dict(type=ZeroRetriever),   # é›¶æ ·æœ¬ç›´æ¥æ‹¿æ¯æ¡æ ·æœ¬ç”¨ prompt
            inferencer=dict(type=GenInferencer)   # é»˜è®¤ greedy / temperature é‡‡æ ·
        ),
        eval_cfg=default_eval_cfg
    ),
]

# ---------------------------------------------------------------------
# 3. æ¨¡å‹
# ---------------------------------------------------------------------
models = [
    dict(
        type='HuggingFaceCausalLM',          # ç›´æ¥å†™å­—ç¬¦ä¸²å³å¯
        abbr='qwen2.5-1.5b',
        path='Qwen/Qwen2.5-1.5B',            # ğŸ¤— æ¨¡å‹ä»“åº“
        tokenizer_path='Qwen/Qwen2.5-1.5B',
        max_out_len=512,
        max_seq_len=8192,                    # Qwen2.5-1.5B å®˜æ–¹ä¸Šä¸‹æ–‡ 8K
        batch_size=1,
        run_cfg=dict(num_gpus=1),
        generation_cfg=dict(                 # å¯é€‰ï¼šå†™ä¸€äº›é‡‡æ ·å‚æ•°
            do_sample=True,
            temperature=0.7,
            top_p=0.95,
        ),
    )
]

# ---------------------------------------------------------------------
# 4. æ¨ç†ä¸è¯„æµ‹ Runner
# ---------------------------------------------------------------------
infer = dict(   # å•æœºå• GPU æ¼”ç¤ºï¼ŒæŒ‰éœ€æ”¹ num_worker
    partitioner=dict(type='NumWorkerPartitioner', num_worker=1),
    runner=dict(type='LocalRunner', task=dict(type='OpenICLInferTask')),
)

eval = dict(    # ROUGE çº¯ CPU å°±è¡Œ
    partitioner=dict(type='NaivePartitioner', n=1),
    runner=dict(type='LocalRunner', task=dict(type='OpenICLEvalTask')),
)

# ---------------------------------------------------------------------
# 5. ç»“æœè¾“å‡ºç›®å½•
# ---------------------------------------------------------------------
work_dir = 'outputs/qwen2p5_1p5b_fin_eval'